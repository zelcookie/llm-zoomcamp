{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f3321b-0aa5-4e7b-91c5-4dc0bd9dbd1c",
   "metadata": {},
   "source": [
    "## Q1. Running Mage\n",
    "\n",
    "What's the version of mage? \n",
    "\n",
    "**v0.9.72**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b6857-a156-499d-bb05-c8ee89ee571a",
   "metadata": {},
   "source": [
    "## Q2. Reading the documents\n",
    "\n",
    "Now we can ingest the documents. Create a custom code ingestion\n",
    "block \n",
    "\n",
    "Let's read the documents. We will use the same code we used\n",
    "for parsing FAQ: [parse-faq-llm.ipynb](parse-faq-llm.ipynb)\n",
    "\n",
    "\n",
    "Use the following document_id: 1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E\n",
    "\n",
    "Which is the document ID of\n",
    "[LLM FAQ version 1](https://docs.google.com/document/d/1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E/edit)\n",
    "\n",
    "Copy the code to the editor\n",
    "How many FAQ documents we processed?\n",
    "\n",
    "* **1**\n",
    "* 2\n",
    "* 3\n",
    "* 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846f609-6bc4-4f1a-a83c-05ea7ab51ebe",
   "metadata": {},
   "source": [
    "## Q3. Chunking\n",
    "\n",
    "\n",
    "How many documents (chunks) do we have in the output?\n",
    "\n",
    "* 66\n",
    "* 76\n",
    "* **86**\n",
    "* 96\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e47e4-3031-41cc-9a06-24b22df1cc64",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
